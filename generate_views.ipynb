{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "metrics_pretty_names = {\n",
    "    'accuracy': 'Accuracy',\n",
    "    'average_total_throughput': 'Average Total Throughput',\n",
    "    'standard_deviation_total_throughput': 'Standard Deviation Total Throughput',\n",
    "    'tpr': 'TPR',\n",
    "    'fpr': 'FPR',\n",
    "    'average_throughput': 'Average Throughput',\n",
    "    'standard_deviation_throughput': 'Standard Deviation Throughput',\n",
    "    'model': 'Model'\n",
    "    \n",
    "}\n",
    "\n",
    "MODELS = ['Random Forest','Decision Tree','MLP','Adaboost', 'Naive Bayes', 'Quadratic Discriminant Analysis','Linear Discriminant Analysis','Logistic Regression','RNN','GRU','Transformer', \"Transformer*\"]\n",
    "pathlib.Path('views/').mkdir(parents=True, exist_ok=True) \n",
    "# Load the data\n",
    "df = pd.read_json('data/results.json', lines=True)\n",
    "df_fids = pd.read_json('data/results_fids.json', lines=True)\n",
    "df = pd.concat([df, df_fids], axis=0)\n",
    "df= df[df['model'].isin(MODELS)]\n",
    "def percentage_transform(df,column):\n",
    "    df[column]=(df[column]*100).map(lambda x: f'{x:.2f}\\\\%')\n",
    "percentage_transform(df,'accuracy')\n",
    "percentage_transform(df,'tpr')\n",
    "percentage_transform(df,'fpr')\n",
    "# Ensure the output_date is in datetime format\n",
    "df['output_date'] = pd.to_datetime(df['output_date'])\n",
    "\n",
    "# Sort the DataFrame by output_date to get the latest entries for each model\n",
    "df_sorted = df.sort_values(by='output_date', ascending=False)\n",
    "\n",
    "# Filter to get the latest result for each model and number of packets combination\n",
    "df_latest = df_sorted.drop_duplicates(subset=['model', 'number_packets'], keep='first')\n",
    "\n",
    "# Separate the results_fids models from the others\n",
    "df_fids_models = df_latest[df_latest['model'].isin(df_fids['model'])]\n",
    "df_other_models = df_latest[~df_latest['model'].isin(df_fids['model'])]\n",
    "\n",
    "# Concatenate the fids models at the top\n",
    "df_latest = pd.concat([df_fids_models, df_other_models], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(obj):\n",
    "    attrs = ['__add__', '__sub__', '__mul__', '__truediv__', '__pow__']\n",
    "    return all(hasattr(obj, attr) for attr in attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "inflect_engine = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('views/variables.tex','w') as f:\n",
    "    df_rounded = df_latest.round(1)\n",
    "    for k,v in df_rounded.iterrows():\n",
    "        for i in ['accuracy','tpr','fpr','average_total_throughput']:\n",
    "            np=v['number_packets']\n",
    "            if is_numeric(np):\n",
    "                np=inflect_engine.number_to_words(np)\n",
    "            words=(v['model'],i,np)\n",
    "            words=map(str,words)\n",
    "            var_name = ''.join(map(str.capitalize, words))\n",
    "            \n",
    "            var_name =var_name.replace('*','star').replace(' ','').replace('_','')\n",
    "            f.write(r'\\newcommand{\\%s}{%s\\xspace}'%(var_name,v[i]))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_packets                            model        2        6       20  \\\n",
      "4                                 Random Forest   9.51\\%  38.71\\%  70.27\\%   \n",
      "5                                 Decision Tree   9.40\\%  30.23\\%  48.40\\%   \n",
      "6                                           MLP   8.33\\%  12.04\\%  12.58\\%   \n",
      "7                                      Adaboost   8.33\\%  15.94\\%  23.05\\%   \n",
      "8                                   Naive Bayes   8.33\\%  12.06\\%  12.05\\%   \n",
      "9               Quadratic Discriminant Analysis  16.72\\%  33.66\\%  45.59\\%   \n",
      "10                 Linear Discriminant Analysis  14.62\\%  30.71\\%  49.60\\%   \n",
      "11                          Logistic Regression   8.34\\%   8.32\\%   9.45\\%   \n",
      "1                                           RNN  33.20\\%  71.20\\%  72.47\\%   \n",
      "2                                           GRU  30.07\\%  70.51\\%  72.54\\%   \n",
      "3                                   Transformer  43.11\\%  80.73\\%  97.50\\%   \n",
      "0                                  Transformer*  34.14\\%  84.22\\%  92.92\\%   \n",
      "\n",
      "number_packets       50     full  \n",
      "4               68.36\\%  55.96\\%  \n",
      "5               52.10\\%  65.45\\%  \n",
      "6               12.59\\%  25.48\\%  \n",
      "7               23.04\\%  23.18\\%  \n",
      "8               12.12\\%  25.08\\%  \n",
      "9               45.61\\%  46.17\\%  \n",
      "10              52.44\\%  52.41\\%  \n",
      "11               9.45\\%  26.27\\%  \n",
      "1               78.26\\%  80.28\\%  \n",
      "2               79.18\\%  80.58\\%  \n",
      "3               98.51\\%  97.42\\%  \n",
      "0               99.30\\%  99.51\\%  \n",
      "number_packets                            model           2           6  \\\n",
      "4                                 Random Forest    2.406692    2.321094   \n",
      "5                                 Decision Tree    2.519360    2.422611   \n",
      "6                                           MLP    2.518878    2.421786   \n",
      "7                                      Adaboost    2.355104    2.256415   \n",
      "8                                   Naive Bayes    2.518776    2.421682   \n",
      "9               Quadratic Discriminant Analysis    2.517790    2.420770   \n",
      "10                 Linear Discriminant Analysis    2.520834    2.423556   \n",
      "11                          Logistic Regression    2.520750    2.423480   \n",
      "1                                           RNN  227.531359  237.781445   \n",
      "2                                           GRU  359.794541  335.327731   \n",
      "3                                   Transformer   69.824169   70.135244   \n",
      "0                                  Transformer*   72.005299   74.490595   \n",
      "\n",
      "number_packets          20          50        full  \n",
      "4                 2.311697    2.321120    0.597083  \n",
      "5                 2.411258    2.423335    0.600463  \n",
      "6                 2.411835    2.422957    0.600440  \n",
      "7                 2.244311    2.254360    0.590743  \n",
      "8                 2.411052    2.422652    0.600444  \n",
      "9                 2.410227    2.422018    0.600394  \n",
      "10                2.413065    2.424670    0.600552  \n",
      "11                2.413002    2.424742    0.600545  \n",
      "1               232.858558  238.506057  226.808450  \n",
      "2               343.787177  345.886129  330.124089  \n",
      "3                65.568117   70.330056   68.764068  \n",
      "0                72.983846   70.584296   66.907394  \n",
      "number_packets                            model          2          6  \\\n",
      "4                                 Random Forest   0.479018   0.509401   \n",
      "5                                 Decision Tree   0.522822   0.552499   \n",
      "6                                           MLP   0.522678   0.552181   \n",
      "7                                      Adaboost   0.459256   0.482061   \n",
      "8                                   Naive Bayes   0.522640   0.552129   \n",
      "9               Quadratic Discriminant Analysis   0.522235   0.551726   \n",
      "10                 Linear Discriminant Analysis   0.523453   0.552956   \n",
      "11                          Logistic Regression   0.523421   0.552922   \n",
      "1                                           RNN  26.103964  22.418667   \n",
      "2                                           GRU  31.081960  50.191155   \n",
      "3                                   Transformer   6.480238   6.816712   \n",
      "0                                  Transformer*   7.747477   5.003189   \n",
      "\n",
      "number_packets         20         50       full  \n",
      "4                0.492136   0.472211   0.480469  \n",
      "5                0.533977   0.512820   0.491961  \n",
      "6                0.534301   0.512709   0.491888  \n",
      "7                0.465434   0.446564   0.459497  \n",
      "8                0.533925   0.512540   0.491901  \n",
      "9                0.533607   0.512341   0.491726  \n",
      "10               0.534787   0.513392   0.492306  \n",
      "11               0.534780   0.513451   0.492224  \n",
      "1               29.676664  24.697972  33.967455  \n",
      "2               44.411496  44.414048  57.198434  \n",
      "3                8.962315   6.979458   7.509275  \n",
      "0                4.767826   8.774442   9.388073  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import constants\n",
    "# Define the function to generate LaTeX table and save to a file\n",
    "def generate_latex_table(df, metric, file_path):\n",
    "    # Pivot the DataFrame to have model as the index and number_packets as columns\n",
    "    # print(df)\n",
    "    npoptions=constants.NUMBER_PACKETS_OPTIONS + ['full']\n",
    "    df_pivot = df.pivot(index='model', columns='number_packets', values=metric).reindex(index=df['model'].unique(), columns=npoptions)\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    # Define the columns for the table\n",
    "    columns = ['model'] + [col for col in df_pivot.columns if col not in ['model', 'confusion_matrix']]\n",
    "    columns_packet_numbers = df_pivot.columns[1:]\n",
    "    columns_packet_numbers = list(columns_packet_numbers)\n",
    "    columns_packet_numbers.remove('full')\n",
    "    \n",
    "    # Extract the packet numbers for the caption\n",
    "    packet_numbers = \", \".join(map(str, columns_packet_numbers))  # Exclude 'Model' column\n",
    "    df_pivot = pd.concat([df_pivot[df_pivot['model']==model] for model in MODELS],axis=0)\n",
    "    print(df_pivot)\n",
    "    # LaTeX table generation function with multi-row header\n",
    "    def df_to_latex_pivot(df, columns):\n",
    "        columns_str = list(map(str, columns))\n",
    "        # Number of packets columns\n",
    "        num_packet_cols = columns_str[1:]\n",
    "        num_packet_cols[-1] = 'Complete Flows'\n",
    "        \n",
    "        latex_table = \"\\\\begin{table*}\\n\\\\centering\\n\"+r'\\begin{adjustbox}{width=\\textwidth}'+\"\\n\\\\begin{tabular}{|c|\" + \"c|\" * len(num_packet_cols) + \"}\\n\\\\hline\\n\"\n",
    "        \n",
    "        # Multi-row header\n",
    "        latex_table += \"\\\\multirow{2}{*}{Model} & \\\\multicolumn{\" + str(len(num_packet_cols)) + \"}{c|}{Number of Packets} \\\\\\\\\\n\\\\cline{2-\" + str(len(columns)) + \"}\\n\"\n",
    "        latex_table += \" & \" + \" & \".join(num_packet_cols) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            latex_table += \" & \".join([f\"{row[col]:.3f}\" if isinstance(row[col], float) else str(row[col]) for col in columns]) + \" \\\\\\\\\\n\"\n",
    "        \n",
    "        latex_table += \"\\\\hline\\n\\\\end{tabular}\\n\"+r'\\end{adjustbox}'+\"\\n\\\\caption{\" + metrics_pretty_names[metric] + \" by Model for Flows with at Most \" + packet_numbers + \" Packets, and Complete Flows}\\n\\\\label{tab:\" + metric.lower().replace(\" \", \"_\") + \"_results}\\n\\\\end{table*}\"\n",
    "        return latex_table\n",
    "\n",
    "    # Generate the LaTeX table\n",
    "    latex_code = df_to_latex_pivot(df_pivot, columns)\n",
    "    \n",
    "    # Save the LaTeX table to a file\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(latex_code)\n",
    "\n",
    "# Identify all metric columns (excluding non-metric columns)\n",
    "non_metric_columns = ['model', 'number_packets', 'output_date', 'best_parameters', 'timeout']\n",
    "metric_columns = ['accuracy', 'average_total_throughput', 'standard_deviation_total_throughput']\n",
    "\n",
    "# Generate LaTeX tables for all metrics and save to files\n",
    "for metric in metric_columns:\n",
    "    file_path = f'views/{metric.lower().replace(\" \", \"_\").replace(\"/\", \"_\")}_table.tex'\n",
    "    generate_latex_table(df_latest, metric, file_path)\n",
    "\n",
    "# Load the data\n",
    "# df = pd.read_json('data/results.json', lines=True)\n",
    "# df_fids = pd.read_json('data/results_fids.json', lines=True)\n",
    "# df = pd.concat([df, df_fids], axis=0)\n",
    "\n",
    "# # Ensure the output_date is in datetime format\n",
    "# df['output_date'] = pd.to_datetime(df['output_date'])\n",
    "\n",
    "# Filter the DataFrame to include only results for 'full' number of packets\n",
    "df_full_packets = df_latest[df_latest['number_packets'] == 'full']\n",
    "\n",
    "# # Sort the DataFrame by output_date to get the latest entries for each model\n",
    "# df_sorted = df_full_packets.sort_values(by='output_date', ascending=False)\n",
    "\n",
    "# # Filter to get the latest result for each model and number of packets combination\n",
    "# df_latest_full = df_sorted.drop_duplicates(subset=['model'], keep='first')\n",
    "\n",
    "# # Separate the results_fids models from the others\n",
    "# df_fids_full_models = df_latest_full[df_latest_full['model'].isin(df_fids['model'])]\n",
    "# df_other_full_models = df_latest_full[~df_latest_full['model'].isin(df_fids['model'])]\n",
    "\n",
    "# # Concatenate the fids models at the top\n",
    "# df_latest_full = pd.concat([df_fids_full_models, df_other_full_models], axis=0)\n",
    "\n",
    "# Define the function to generate LaTeX table and save to a file\n",
    "def generate_latex_table_full(df, file_path):\n",
    "    # Define the columns for the table\n",
    "    # excluded_columns = [\n",
    "    #     'model', 'number_packets', 'output_date', 'best_parameters', 'timeout', \n",
    "    #     'confusion_matrix', '', 'precision', 'recall', 'confusion_matrix', 'Average Prediction Time (s/sample)', \n",
    "    #     'Standard Deviation Prediction Time (s/sample)', \n",
    "    #     'Average Throughput (samples/s)', \n",
    "    #     'Standard Deviation Throughput (samples/s)'\n",
    "    # ]\n",
    "\n",
    "    # columns = ['model'] + [col for col in df.columns if col not in excluded_columns]\n",
    "    columns= ['model','accuracy','tpr','fpr',\"average_throughput\",\"average_total_throughput\"]\n",
    "    # LaTeX table generation function\n",
    "    def df_to_latex_pivot(df, columns):\n",
    "        columns_str = list(map(str, columns))\n",
    "        latex_table = \"\\\\begin{table*}\\n\\\\centering\\n\"+r'\\begin{adjustbox}{width=\\textwidth}'+\"\\n\\\\begin{tabular}{|\" + \" | \".join([\"c\"] * len(columns)) + \"|}\\n\\\\hline\\n\"\n",
    "        latex_table += \" & \".join(map(lambda x : metrics_pretty_names[x], columns_str)) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "        for _, row in df.iterrows():\n",
    "            latex_table += \" & \".join([f\"{row[col]:.4f}\" if isinstance(row[col], float) else str(row[col]) for col in columns]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        latex_table += \"\\\\hline\\n\\\\end{tabular}\"+r\"\\end{adjustbox}\"+\"\\n\\\\caption{Results across multiple metrics with all complete flows.}\\n\\\\label{tab:full_packets_results}\\n\\\\end{table*}\"\n",
    "        return latex_table\n",
    "    df = pd.concat([df[df['model']==model] for model in MODELS],axis=0)\n",
    "    # Generate the LaTeX table\n",
    "    latex_code = df_to_latex_pivot(df, columns)\n",
    "    \n",
    "    # Save the LaTeX table to a file\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(latex_code)\n",
    "\n",
    "# Define the file path for the LaTeX table\n",
    "file_path = 'views/full_packets_results.tex'\n",
    "\n",
    "# Generate LaTeX table for full number of packets and save to a file\n",
    "generate_latex_table_full(df_full_packets, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
